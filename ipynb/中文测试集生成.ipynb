{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add ragas langchain-openai langchain-community pandas ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 下载和加载中文语料库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 准备中文数据集（比如中国四大名著）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/tennessine/corpus.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 使用LangChain加载中文文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "# 指向包含中文文本的目录\n",
    "path = \"corpus/\"\n",
    "loader = DirectoryLoader(path, glob=\"**/*.md\", loader_cls=TextLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(docs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 初始化支持中文的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "from pydantic import SecretStr\n",
    "\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\".env\", env_file_encoding=\"utf-8\", extra=\"ignore\", case_sensitive=False\n",
    "    )\n",
    "    openai_api_key: SecretStr\n",
    "    openai_base_url: str\n",
    "    openai_model: str  # 评估用LLM\n",
    "    openai_embedding_model: str  # 嵌入模型\n",
    "    temperature: int = 0  # 固定随机种子，确保评估结果稳定\n",
    "\n",
    "\n",
    "config = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=config.openai_base_url,\n",
    "    api_key=config.openai_api_key,\n",
    "    model=config.openai_model,\n",
    "    temperature=config.temperature,\n",
    ")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=config.openai_embedding_model,\n",
    "    base_url=config.openai_base_url,\n",
    "    api_key=config.openai_api_key,\n",
    ")\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(llm)\n",
    "generator_embedding = LangchainEmbeddingsWrapper(embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 设置中文角色和转换工具\n",
    "### 1.3.1 定义中文场景的用户角色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.persona import Persona\n",
    "\n",
    "personas = [\n",
    "    Persona(\n",
    "        name=\"中文四大名著学习者\",\n",
    "        role_description=\"  一位对中国古典文学四大名著（《红楼梦》、《三国演义》、《水浒传》、《西游记》）感兴趣的学习者，希望通过查询深入了解这些作品的内容、背景和文学价值。\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 配置中文适用的转换工具（如标题分割、实体提取）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms.extractors.llm_based import NERExtractor\n",
    "from ragas.testset.transforms.splitters import HeadlineSplitter\n",
    "\n",
    "transforms = [HeadlineSplitter(), NERExtractor(llm=generator_llm)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 初始化测试生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=generator_embedding,\n",
    "    persona_list=personas,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 加载查询类型并适配中文\n",
    "### 1.5.1 定义单跳查询生成器并适配中文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.single_hop.specific import (\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    ")\n",
    "\n",
    "\n",
    "distribution = [\n",
    "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 1.0),\n",
    "]\n",
    "# 将查询提示词适配为中文\n",
    "for query, _ in distribution:\n",
    "    prompts = await query.adapt_prompts(\n",
    "        \"chinese\", llm=generator_llm\n",
    "    )  # 指定目标语言为中文\n",
    "    query.set_prompts(**prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 生成中文测试集\n",
    "### 1.6.1 基于中文文档生成查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = generator.generate_with_langchain_docs(\n",
    "    docs,\n",
    "    testset_size=3,  # 生成3条中文查询\n",
    "    transforms=transforms,\n",
    "    query_distribution=distribution,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.2 转换为评估数据集并查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = dataset.to_evaluation_dataset()\n",
    "# 打印第一条中文查询和参考文本\n",
    "print(\"用户查询:\", eval_dataset[0].user_input)\n",
    "print(\"参考回答:\", eval_dataset[0].reference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
